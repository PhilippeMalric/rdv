<h4>Le taux de faux positifs (« False positive rate »)</h4>
<p>
  Le taux de faux positifs est le nombre de faux positifs divisé par le nombre total d’éléments négatifs. Autrement dit, c’est le nombre d’éléments prédits positifs, mais qui sont en réalité négatifs divisé par le nombre total d’éléments négatif. L’axe des abscisses (horizontale) du plan de la courbe ROC est le taux de faux positifs. En général, moins la sensibilité ou le rappel est grand, moins le taux de faux positifs est grand, c’est ce que la courbe « ROC » illustre. Ceci est vrai pour les algorithmes tel que les classifieurs bayésiens naïfs puisqu’ils donnent une probabilité d’appartenance à une classe [41]. Plus on augmente le seuil de risque que prend l’algorithme, plus le nombre total de vrais positifs augmente, mais de moins en moins rapidement. L’augmentation du risque que prend l’algorithme entraine aussi le nombre de faux positifs à la hausse. Un algorithme risqué prédit plus d’éléments dans la classe des positifs qu’un algorithme peu risqué. Un bon algorithme à un rapport élevé entre le taux de vrais positifs et le taux de faux positifs.
</p>
